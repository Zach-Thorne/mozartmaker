{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import pylab\n",
    "import os\n",
    "from struct import pack\n",
    "from sys import byteorder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "from scipy.io import wavfile as wav\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "from collections import Counter\n",
    "from array import array\n",
    "from pydub.silence import split_on_silence\n",
    "import crepe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White keys are in Uppercase and black keys (sharps) are in lowercase\n",
    "octave = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'] \n",
    "base_freq = 440 #Frequency of Note A4\n",
    "keys = np.array([x+str(y) for y in range(0,9) for x in octave])\n",
    "# Trim to correct # keys\n",
    "start = np.where(keys == 'A0')[0][0]\n",
    "end = np.where(keys == 'C8')[0][0]\n",
    "keys = keys[start:end+1]\n",
    "\n",
    "note_freqs = list(([2**((n-48)/12)*base_freq for n in range(len(keys))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.6255653005986, 293.6647679174076, 329.6275569128699, 349.2282314330039, 391.99543598174927]\n"
     ]
    }
   ],
   "source": [
    "c_major_scale_freqs=[]\n",
    "c_major_scale=['C4', 'D4', 'E4', 'F4', 'G4']\n",
    "for i in range(len(keys)):\n",
    "    for j in range(5):\n",
    "        if c_major_scale[j]==keys[i]:\n",
    "            c_major_scale_freqs.append(note_freqs[i])\n",
    "print(c_major_scale_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_value(input_list, input_value):\n",
    "\n",
    "  arr = np.asarray(input_list)\n",
    "\n",
    "  i = (np.abs(arr - input_value)).argmin()\n",
    "\n",
    "  return arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "CHUNK = 1024*4          # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 48000                 # samples per second\n",
    "RECORD_SECONDS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "p.get_device_info_by_index(3)['defaultSampleRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* listening\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* recording\n",
      "* done\n"
     ]
    }
   ],
   "source": [
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "# create matplotlib figure and axes\n",
    "#fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "#p.get_device_info_by_index(3)['defaultSampleRate']\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    #input_device_index =3, #change this according to the mic port on your computer\n",
    "    input=True,output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "frames = []\n",
    "print(\"* listening\")\n",
    "\n",
    "while 1:\n",
    "    \n",
    "    data = stream.read(CHUNK, exception_on_overflow = False)\n",
    "    data_chunk=array('h',data)\n",
    "    vol=max(data_chunk)\n",
    "    if vol >= 400:\n",
    "        print(\"* recording\")\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            stream.write(data, CHUNK)\n",
    "            frames.append(data)\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(\"* waiting\")\n",
    "\n",
    "print(\"* done\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "p.terminate()\n",
    "file_path='/Users/emmarobinson/Downloads/piano_audio.wav' #change this according to your computer file\n",
    "file_name = file_path.split('/')[-1]\n",
    "wf = wave.open(file_path, \"wb\")\n",
    "# set the channels\n",
    "wf.setnchannels(CHANNELS)\n",
    "# set the sample format\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# set the sample rate\n",
    "wf.setframerate(RATE)\n",
    "# write the frames as bytes\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "# close the file\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/emmarobinson/Downloads/piano_audio_new.wav'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I dont know if we need this tbh\n",
    "sound = AudioSegment.from_file(file_path, format = 'wav') \n",
    "audio_chunks = split_on_silence(sound\n",
    "                            ,min_silence_len = 100\n",
    "                            ,silence_thresh = -45\n",
    "                            ,keep_silence = 50\n",
    "                        )\n",
    "\n",
    "# Putting the file back together\n",
    "combined = AudioSegment.empty()\n",
    "for chunk in audio_chunks:\n",
    "    combined += chunk\n",
    "combined.export(f'/Users/emmarobinson/Downloads/piano_audio_new.wav', format = 'wav') #change this according to your computer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 378ms/step\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wav.read('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "time, frequency, confidence, activation = crepe.predict(audio, sr, viterbi=True, model_capacity=\"small\")\n",
    "freq1=np.array([np.mean(frequency)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C#6']\n"
     ]
    }
   ],
   "source": [
    "song_notes=[]\n",
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    song_notes.append(keys[index])\n",
    "    print(song_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    played_note=keys[index]\n",
    "\n",
    "x=0\n",
    "if played_note==c_major_scale[x]:\n",
    "    print(\"yay\")\n",
    "else:\n",
    "        print(\"try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wav.read('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "audio_segment = AudioSegment.from_file('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "duration = len(audio_segment)/1000\n",
    "\n",
    "# calculate the length of our chunk in the np.array using sample rate\n",
    "chunk = int(rate * duration)\n",
    "\n",
    "# length of delimiting 1600hz tone\n",
    "offset = int(rate * 0.005)\n",
    "\n",
    "# number of bits in the audio data to decode\n",
    "bits = int(len(data) / chunk)\n",
    "\n",
    "def get_freq(bit):\n",
    "    # start position of the current bit\n",
    "    strt = (chunk * bit) \n",
    "    \n",
    "    # remove the delimiting 1600hz tone\n",
    "    end = (strt + chunk) \n",
    "   \n",
    "    \n",
    "    # slice the array for each bit\n",
    "    sliced = data[strt:end]\n",
    "\n",
    "    w = np.fft.fft(sliced)\n",
    "    w=np.absolute(w)\n",
    "    freqs = np.fft.fftfreq(len(w))\n",
    "\n",
    "    \n",
    "\n",
    "    # Find the peak in the coefficients\n",
    "    idx = np.argmax(np.abs(w))\n",
    "    freq = freqs[idx]\n",
    "    freq_in_hertz = abs(freq * rate)\n",
    "    return freq_in_hertz\n",
    "\n",
    "decoded_freqs = [get_freq(bit) for bit in range(bits)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
