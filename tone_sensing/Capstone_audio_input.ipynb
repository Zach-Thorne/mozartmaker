{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import os\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PyQt5 import QtWidgets, QtCore\n",
    "import PyQt5 as pg\n",
    "import scipy\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "from scipy.io import wavfile as wav\n",
    "import wave\n",
    "import soundfile as sf\n",
    "from pydub import AudioSegment\n",
    "from pyqtgraph.Qt import QtWidgets, QtCore\n",
    "import math\n",
    "from collections import Counter\n",
    "from pydub.utils import get_array_type\n",
    "import array\n",
    "from pydub.silence import split_on_silence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # White keys are in Uppercase and black keys (sharps) are in lowercase\n",
    "octave = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'] \n",
    "base_freq = 440 #Frequency of Note A4\n",
    "keys = np.array([x+str(y) for y in range(0,9) for x in octave])\n",
    "# Trim to correct # keys\n",
    "start = np.where(keys == 'A0')[0][0]\n",
    "end = np.where(keys == 'C8')[0][0]\n",
    "keys = keys[start:end+1]\n",
    "\n",
    "note_freqs = list(([2**((n+1-49)/12)*base_freq for n in range(len(keys))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.6255653005986, 293.6647679174076, 329.6275569128699, 349.2282314330039, 391.99543598174927]\n"
     ]
    }
   ],
   "source": [
    "c_major_scale_freqs=[]\n",
    "c_major_scale=['C4', 'D4', 'E4', 'F4', 'G4']\n",
    "for i in range(len(keys)):\n",
    "    for j in range(5):\n",
    "        if c_major_scale[j]==keys[i]:\n",
    "            c_major_scale_freqs.append(note_freqs[i])\n",
    "print(c_major_scale_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_value(input_list, input_value):\n",
    "\n",
    "  arr = np.asarray(input_list)\n",
    "\n",
    "  i = (np.abs(arr - input_value)).argmin()\n",
    "\n",
    "  return arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib tk\n",
    "\n",
    "# constants\n",
    "CHUNK = 1024*2            # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 44100                 # samples per second\n",
    "RECORD_SECONDS = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done\n"
     ]
    }
   ],
   "source": [
    "os.remove('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "os.remove('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "# create matplotlib figure and axes\n",
    "#fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input_device_index =3, #change this according to the mic port on your computer\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "frames = []\n",
    "print(\"* recording\")\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    stream.write(data, CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "p.terminate()\n",
    "file_path='/Users/emmarobinson/Downloads/piano_audio.wav' #change this according to your computer file\n",
    "file_name = file_path.split('/')[-1]\n",
    "wf = wave.open(file_path, \"wb\")\n",
    "# set the channels\n",
    "wf.setnchannels(CHANNELS)\n",
    "# set the sample format\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# set the sample rate\n",
    "wf.setframerate(RATE)\n",
    "# write the frames as bytes\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "# close the file\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/emmarobinson/Downloads/piano_audio_new.wav'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound = AudioSegment.from_file(file_path, format = 'wav') \n",
    "audio_chunks = split_on_silence(sound\n",
    "                            ,min_silence_len = 100\n",
    "                            ,silence_thresh = -45\n",
    "                            ,keep_silence = 50\n",
    "                        )\n",
    "\n",
    "# Putting the file back together\n",
    "combined = AudioSegment.empty()\n",
    "for chunk in audio_chunks:\n",
    "    combined += chunk\n",
    "combined.export(f'/Users/emmarobinson/Downloads/piano_audio_new.wav', format = 'wav') #change this according to your computer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wav.read('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "audio_segment = AudioSegment.from_file('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "duration = len(audio_segment)/1000\n",
    "\n",
    "# calculate the length of our chunk in the np.array using sample rate\n",
    "chunk = int(rate * duration)\n",
    "\n",
    "# length of delimiting 1600hz tone\n",
    "offset = int(rate * 0.005)\n",
    "\n",
    "# number of bits in the audio data to decode\n",
    "bits = int(len(data) / chunk)\n",
    "\n",
    "def get_freq(bit):\n",
    "    # start position of the current bit\n",
    "    strt = (chunk * bit) \n",
    "    \n",
    "    # remove the delimiting 1600hz tone\n",
    "    end = (strt + chunk) \n",
    "   \n",
    "    \n",
    "    # slice the array for each bit\n",
    "    sliced = data[strt:end]\n",
    "\n",
    "    w = np.fft.fft(sliced)\n",
    "    w=np.absolute(w)\n",
    "    freqs = np.fft.fftfreq(len(w))\n",
    "\n",
    "    \n",
    "\n",
    "    # Find the peak in the coefficients\n",
    "    idx = np.argmax(np.abs(w))\n",
    "    freq = freqs[idx]\n",
    "    freq_in_hertz = abs(freq * rate)\n",
    "    return freq_in_hertz\n",
    "\n",
    "decoded_freqs = [get_freq(bit) for bit in range(bits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded_freqs)):\n",
    "    note=closest_value(note_freqs,decoded_freqs[i])\n",
    "    index = note_freqs.index(note)\n",
    "    print(keys[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yay\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded_freqs)):\n",
    "    note=closest_value(note_freqs,decoded_freqs[i])\n",
    "    index = note_freqs.index(note)\n",
    "    played_note=keys[index]\n",
    "\n",
    "x=0\n",
    "if played_note==c_major_scale[x]:\n",
    "    print(\"yay\")\n",
    "else:\n",
    "        print(\"try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ax1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m xf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, RATE, CHUNK)     \u001b[39m# frequencies (spectrum)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# create a line object with random data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m line, \u001b[39m=\u001b[39m ax1\u001b[39m.\u001b[39mplot(x, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(CHUNK), \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# create semilogx line for spectrum\u001b[39;00m\n\u001b[1;32m      9\u001b[0m line_fft, \u001b[39m=\u001b[39m ax2\u001b[39m.\u001b[39msemilogx(xf, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(CHUNK), \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ax1' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)       # samples (waveform)\n",
    "xf = np.linspace(0, RATE, CHUNK)     # frequencies (spectrum)\n",
    "\n",
    "# create a line object with random data\n",
    "line, = ax1.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# create semilogx line for spectrum\n",
    "line_fft, = ax2.semilogx(xf, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# format waveform axes\n",
    "ax1.set_title('AUDIO WAVEFORM')\n",
    "ax1.set_xlabel('samples')\n",
    "ax1.set_ylabel('volume')\n",
    "ax1.set_ylim(0, 255)\n",
    "ax1.set_xlim(0, 2 * CHUNK)\n",
    "plt.setp(ax1, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "# format spectrum axes\n",
    "ax2.set_xlim(20, RATE / 2)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # binary data\n",
    "    data = stream.read(CHUNK,exception_on_overflow = False)  \n",
    "    \n",
    "    # convert data to integers, make np array, then offset it by 127\n",
    "    data_int = np.frombuffer(data, dtype='h')  \n",
    "    data_np = np.array(data_int, dtype='h')/140 + 255\n",
    "    \n",
    "    line.set_ydata(data_np)\n",
    "    \n",
    "    # compute FFT and update line\n",
    "    yf = fft(data_int)\n",
    "    line_fft.set_ydata(np.abs(yf[0:CHUNK])  / (128 * CHUNK))\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "                # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "        break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels: 1\n",
      "Sample width: 2\n",
      "Frame rate (sample rate): 8000\n",
      "Frame width: 2\n",
      "Length (ms): 8001\n",
      "Frame count: 64004.0\n",
      "Intensity: -3.0108529080336788\n"
     ]
    }
   ],
   "source": [
    "audio_segment = AudioSegment.from_file('/Users/emmarobinson/Downloads/c-major-scale.wav')\n",
    "# Print attributes\n",
    "print(f\"Channels: {audio_segment.channels}\")\n",
    "print(f\"Sample width: {audio_segment.sample_width}\")\n",
    "print(f\"Frame rate (sample rate): {audio_segment.frame_rate}\")\n",
    "print(f\"Frame width: {audio_segment.frame_width}\")\n",
    "print(f\"Length (ms): {len(audio_segment)}\")\n",
    "print(f\"Frame count: {audio_segment.frame_count()}\")\n",
    "print(f\"Intensity: {audio_segment.dBFS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C8\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(decoded_freqs)):\n",
    "    note=closest_value(note_freqs,decoded_freqs[i])\n",
    "    index = note_freqs.index(note)\n",
    "    print(keys[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
