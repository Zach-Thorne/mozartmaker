{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import pylab\n",
    "import os\n",
    "from struct import pack\n",
    "from sys import byteorder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PyQt5 import QtWidgets, QtCore\n",
    "import PyQt5 as pg\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "from scipy.io import wavfile as wav\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "import math\n",
    "from collections import Counter\n",
    "from array import array\n",
    "from pydub.silence import split_on_silence\n",
    "import datetime\n",
    "import crepe\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White keys are in Uppercase and black keys (sharps) are in lowercase\n",
    "octave = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'] \n",
    "base_freq = 440 #Frequency of Note A4\n",
    "keys = np.array([x+str(y) for y in range(0,9) for x in octave])\n",
    "# Trim to correct # keys\n",
    "start = np.where(keys == 'A0')[0][0]\n",
    "end = np.where(keys == 'C8')[0][0]\n",
    "keys = keys[start:end+1]\n",
    "\n",
    "note_freqs = list(([2**((n-48)/12)*base_freq for n in range(len(keys))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.6255653005986, 293.6647679174076, 329.6275569128699, 349.2282314330039, 391.99543598174927]\n"
     ]
    }
   ],
   "source": [
    "c_major_scale_freqs=[]\n",
    "c_major_scale=['C4', 'D4', 'E4', 'F4', 'G4']\n",
    "for i in range(len(keys)):\n",
    "    for j in range(5):\n",
    "        if c_major_scale[j]==keys[i]:\n",
    "            c_major_scale_freqs.append(note_freqs[i])\n",
    "print(c_major_scale_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_value(input_list, input_value):\n",
    "\n",
    "  arr = np.asarray(input_list)\n",
    "\n",
    "  i = (np.abs(arr - input_value)).argmin()\n",
    "\n",
    "  return arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "CHUNK = 1024*4          # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 48000                 # samples per second\n",
    "RECORD_SECONDS = 1\n",
    "THRESHOLD=500\n",
    "TRIM_APPEND = RATE / 4\n",
    "FRAME_MAX_VALUE = 2 ** 15 - 1\n",
    "NORMALIZE_MINUS_ONE_dB = 10 ** (-1.0 / 20)\n",
    "SILENT_CHUNKS = (3 * RATE / CHUNK)  # about 1sec\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "p.get_device_info_by_index(3)['defaultSampleRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_silent(snd_data):\n",
    "    \"Returns 'True' if below the 'silent' threshold\"\n",
    "    return max(snd_data) < THRESHOLD\n",
    "\n",
    "def normalize(data_all):\n",
    "    \"\"\"Amplify the volume out to max -1dB\"\"\"\n",
    "    # MAXIMUM = 16384\n",
    "    normalize_factor = (float(NORMALIZE_MINUS_ONE_dB * FRAME_MAX_VALUE)\n",
    "                        / max(abs(i) for i in data_all))\n",
    "\n",
    "    r = array('h')\n",
    "    for i in data_all:\n",
    "        r.append(int(i * normalize_factor))\n",
    "    return r\n",
    "def trim(data_all):\n",
    "    _from = 0\n",
    "    _to = len(data_all) - 1\n",
    "    for i, b in enumerate(data_all):\n",
    "        if abs(b) > THRESHOLD:\n",
    "            _from = max(0, i - TRIM_APPEND)\n",
    "            break\n",
    "\n",
    "    for i, b in enumerate(reversed(data_all)):\n",
    "        if abs(b) > THRESHOLD:\n",
    "            _to = min(len(data_all) - 1, len(data_all) - 1 - i + TRIM_APPEND)\n",
    "            break\n",
    "\n",
    "    return copy.deepcopy(data_all[int(_from):(int(_to) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "integer argument expected, got float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [91], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m     wave_file\u001b[39m.\u001b[39mwriteframes(data)\n\u001b[1;32m     50\u001b[0m     wave_file\u001b[39m.\u001b[39mclose()\n\u001b[0;32m---> 52\u001b[0m record_to_file(\u001b[39m'\u001b[39;49m\u001b[39m/Users/emmarobinson/Downloads/piano_audio_new.wav\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [91], line 42\u001b[0m, in \u001b[0;36mrecord_to_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecord_to_file\u001b[39m(path):\n\u001b[1;32m     41\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRecords from the microphone and outputs the resulting data to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m     sample_width, data \u001b[39m=\u001b[39m record()\n\u001b[1;32m     43\u001b[0m     data \u001b[39m=\u001b[39m pack(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m (\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data)), \u001b[39m*\u001b[39mdata)\n\u001b[1;32m     45\u001b[0m     wave_file \u001b[39m=\u001b[39m wave\u001b[39m.\u001b[39mopen(path, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [91], line 6\u001b[0m, in \u001b[0;36mrecord\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\"\"\"Record a word or words from the microphone and \u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mreturn the data as an array of signed shorts.\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m p \u001b[39m=\u001b[39m pyaudio\u001b[39m.\u001b[39mPyAudio()\n\u001b[0;32m----> 6\u001b[0m stream \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mopen(\u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49mFORMAT, channels\u001b[39m=\u001b[39;49mCHANNELS, rate\u001b[39m=\u001b[39;49mRATE, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, frames_per_buffer\u001b[39m=\u001b[39;49mSILENT_CHUNKS)\n\u001b[1;32m      8\u001b[0m silent_chunks \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      9\u001b[0m audio_started \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyaudio.py:754\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    747\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[39m    Open a new stream. See constructor for\u001b[39;00m\n\u001b[1;32m    749\u001b[0m \u001b[39m    :py:func:`Stream.__init__` for parameter details.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \n\u001b[1;32m    751\u001b[0m \u001b[39m    :returns: A new :py:class:`Stream`\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 754\u001b[0m     stream \u001b[39m=\u001b[39m Stream(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    755\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streams\u001b[39m.\u001b[39madd(stream)\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyaudio.py:445\u001b[0m, in \u001b[0;36mStream.__init__\u001b[0;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[1;32m    442\u001b[0m     arguments[\u001b[39m'\u001b[39m\u001b[39mstream_callback\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m stream_callback\n\u001b[1;32m    444\u001b[0m \u001b[39m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mopen(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marguments)\n\u001b[1;32m    447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39minputLatency\n\u001b[1;32m    448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39moutputLatency\n",
      "\u001b[0;31mTypeError\u001b[0m: integer argument expected, got float"
     ]
    }
   ],
   "source": [
    "def record():\n",
    "    \"\"\"Record a word or words from the microphone and \n",
    "    return the data as an array of signed shorts.\"\"\"\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, output=True, frames_per_buffer=SILENT_CHUNKS)\n",
    "\n",
    "    silent_chunks = 0\n",
    "    audio_started = False\n",
    "    data_all = array('h')\n",
    "\n",
    "    while True:\n",
    "        # little endian, signed short\n",
    "        data_chunk = array('h', stream.read(CHUNK))\n",
    "        if byteorder == 'big':\n",
    "            data_chunk.byteswap()\n",
    "        data_all.extend(data_chunk)\n",
    "\n",
    "        silent = is_silent(data_chunk)\n",
    "\n",
    "        if audio_started:\n",
    "            if silent:\n",
    "                silent_chunks += 1\n",
    "                if silent_chunks > SILENT_CHUNKS:\n",
    "                    break\n",
    "            else: \n",
    "                silent_chunks = 0\n",
    "        elif not silent:\n",
    "            audio_started = True              \n",
    "\n",
    "    sample_width = p.get_sample_size(FORMAT)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    data_all = trim(data_all)  # we trim before normalize as threshhold applies to un-normalized wave (as well as is_silent() function)\n",
    "    data_all = normalize(data_all)\n",
    "    return sample_width, data_all\n",
    "\n",
    "def record_to_file(path):\n",
    "    \"Records from the microphone and outputs the resulting data to 'path'\"\n",
    "    sample_width, data = record()\n",
    "    data = pack('<' + ('h' * len(data)), *data)\n",
    "\n",
    "    wave_file = wave.open(path, 'wb')\n",
    "    wave_file.setnchannels(CHANNELS)\n",
    "    wave_file.setsampwidth(sample_width)\n",
    "    wave_file.setframerate(RATE)\n",
    "    wave_file.writeframes(data)\n",
    "    wave_file.close()\n",
    "\n",
    "record_to_file('/Users/emmarobinson/Downloads/piano_audio_new.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* listening\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* recording\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno Not output stream] -9974",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m* recording\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m(RATE \u001b[39m/\u001b[39m CHUNK \u001b[39m*\u001b[39m RECORD_SECONDS)):\n\u001b[0;32m---> 36\u001b[0m         stream\u001b[39m.\u001b[39;49mwrite(data, CHUNK)\n\u001b[1;32m     37\u001b[0m         frames\u001b[39m.\u001b[39mappend(data)\n\u001b[1;32m     40\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pyaudio.py:580\u001b[0m, in \u001b[0;36mStream.write\u001b[0;34m(self, frames, num_frames, exception_on_underflow)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    558\u001b[0m \u001b[39mWrite samples to the stream.  Do not call when using\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[39m*non-blocking* mode.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m:rtype: `None`\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_output:\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot output stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    581\u001b[0m                   paCanNotWriteToAnInputOnlyStream)\n\u001b[1;32m    583\u001b[0m \u001b[39mif\u001b[39;00m num_frames \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     \u001b[39m# determine how many frames to read\u001b[39;00m\n\u001b[1;32m    585\u001b[0m     width \u001b[39m=\u001b[39m get_sample_size(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno Not output stream] -9974"
     ]
    }
   ],
   "source": [
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "# create matplotlib figure and axes\n",
    "#fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "#p.get_device_info_by_index(3)['defaultSampleRate']\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input_device_index =3, #change this according to the mic port on your computer\n",
    "    input=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "frames = []\n",
    "print(\"* listening\")\n",
    "\n",
    "    \n",
    "\n",
    "#if vol >= 400:\n",
    "\n",
    "\n",
    "while 1:\n",
    "    \n",
    "    data = stream.read(CHUNK, exception_on_overflow = False)\n",
    "    data_chunk=array('h',data)\n",
    "    vol=max(data_chunk)\n",
    "    if vol >= 400:\n",
    "        print(\"* recording\")\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            stream.write(data, CHUNK)\n",
    "            frames.append(data)\n",
    "        \n",
    "\n",
    "    else:\n",
    "        print(\"* waiting\")\n",
    "\n",
    "print(\"* done\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "p.terminate()\n",
    "file_path='/Users/emmarobinson/Downloads/piano_audio.wav' #change this according to your computer file\n",
    "file_name = file_path.split('/')[-1]\n",
    "wf = wave.open(file_path, \"wb\")\n",
    "# set the channels\n",
    "wf.setnchannels(CHANNELS)\n",
    "# set the sample format\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# set the sample rate\n",
    "wf.setframerate(RATE)\n",
    "# write the frames as bytes\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "# close the file\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/emmarobinson/Downloads/piano_audio_new.wav'>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound = AudioSegment.from_file(file_path, format = 'wav') \n",
    "audio_chunks = split_on_silence(sound\n",
    "                            ,min_silence_len = 100\n",
    "                            ,silence_thresh = -45\n",
    "                            ,keep_silence = 50\n",
    "                        )\n",
    "\n",
    "# Putting the file back together\n",
    "combined = AudioSegment.empty()\n",
    "for chunk in audio_chunks:\n",
    "    combined += chunk\n",
    "combined.export(f'/Users/emmarobinson/Downloads/piano_audio_new.wav', format = 'wav') #change this according to your computer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 29s 2s/step\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wav.read('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "time, frequency, confidence, activation = crepe.predict(audio, sr, viterbi=True)\n",
    "freq1=np.array([np.mean(frequency)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D#4\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    print(keys[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    played_note=keys[index]\n",
    "\n",
    "x=0\n",
    "if played_note==c_major_scale[x]:\n",
    "    print(\"yay\")\n",
    "else:\n",
    "        print(\"try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wav.read('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "audio_segment = AudioSegment.from_file('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "duration = len(audio_segment)/1000\n",
    "\n",
    "# calculate the length of our chunk in the np.array using sample rate\n",
    "chunk = int(rate * duration)\n",
    "\n",
    "# length of delimiting 1600hz tone\n",
    "offset = int(rate * 0.005)\n",
    "\n",
    "# number of bits in the audio data to decode\n",
    "bits = int(len(data) / chunk)\n",
    "\n",
    "def get_freq(bit):\n",
    "    # start position of the current bit\n",
    "    strt = (chunk * bit) \n",
    "    \n",
    "    # remove the delimiting 1600hz tone\n",
    "    end = (strt + chunk) \n",
    "   \n",
    "    \n",
    "    # slice the array for each bit\n",
    "    sliced = data[strt:end]\n",
    "\n",
    "    w = np.fft.fft(sliced)\n",
    "    w=np.absolute(w)\n",
    "    freqs = np.fft.fftfreq(len(w))\n",
    "\n",
    "    \n",
    "\n",
    "    # Find the peak in the coefficients\n",
    "    idx = np.argmax(np.abs(w))\n",
    "    freq = freqs[idx]\n",
    "    freq_in_hertz = abs(freq * rate)\n",
    "    return freq_in_hertz\n",
    "\n",
    "decoded_freqs = [get_freq(bit) for bit in range(bits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ax1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m xf \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(\u001b[39m0\u001b[39m, RATE, CHUNK)     \u001b[39m# frequencies (spectrum)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# create a line object with random data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m line, \u001b[39m=\u001b[39m ax1\u001b[39m.\u001b[39mplot(x, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(CHUNK), \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# create semilogx line for spectrum\u001b[39;00m\n\u001b[1;32m      9\u001b[0m line_fft, \u001b[39m=\u001b[39m ax2\u001b[39m.\u001b[39msemilogx(xf, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(CHUNK), \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m, lw\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ax1' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# variable for plotting\n",
    "x = np.arange(0, 2 * CHUNK, 2)       # samples (waveform)\n",
    "xf = np.linspace(0, RATE, CHUNK)     # frequencies (spectrum)\n",
    "\n",
    "# create a line object with random data\n",
    "line, = ax1.plot(x, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# create semilogx line for spectrum\n",
    "line_fft, = ax2.semilogx(xf, np.random.rand(CHUNK), '-', lw=2)\n",
    "\n",
    "# format waveform axes\n",
    "ax1.set_title('AUDIO WAVEFORM')\n",
    "ax1.set_xlabel('samples')\n",
    "ax1.set_ylabel('volume')\n",
    "ax1.set_ylim(0, 255)\n",
    "ax1.set_xlim(0, 2 * CHUNK)\n",
    "plt.setp(ax1, xticks=[0, CHUNK, 2 * CHUNK], yticks=[0, 128, 255])\n",
    "\n",
    "# format spectrum axes\n",
    "ax2.set_xlim(20, RATE / 2)\n",
    "\n",
    "print('stream started')\n",
    "\n",
    "# for measuring frame rate\n",
    "frame_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # binary data\n",
    "    data = stream.read(CHUNK,exception_on_overflow = False)  \n",
    "    \n",
    "    # convert data to integers, make np array, then offset it by 127\n",
    "    data_int = np.frombuffer(data, dtype='h')  \n",
    "    data_np = np.array(data_int, dtype='h')/140 + 255\n",
    "    \n",
    "    line.set_ydata(data_np)\n",
    "    \n",
    "    # compute FFT and update line\n",
    "    yf = fft(data_int)\n",
    "    line_fft.set_ydata(np.abs(yf[0:CHUNK])  / (128 * CHUNK))\n",
    "    \n",
    "    # update figure canvas\n",
    "    try:\n",
    "        fig.canvas.draw()\n",
    "        fig.canvas.flush_events()\n",
    "        frame_count += 1\n",
    "        \n",
    "    except TclError:\n",
    "                # calculate average frame rate\n",
    "        frame_rate = frame_count / (time.time() - start_time)\n",
    "        \n",
    "        print('stream stopped')\n",
    "        print('average frame rate = {:.0f} FPS'.format(frame_rate))\n",
    "        break\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
