{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import pylab\n",
    "import os\n",
    "from struct import pack\n",
    "from sys import byteorder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.fftpack import fft\n",
    "import time\n",
    "from tkinter import TclError\n",
    "from scipy.io import wavfile as wav\n",
    "import wave\n",
    "\n",
    "from collections import Counter\n",
    "from array import array\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "0 (b'CoreMIDI', b'CASIO USB-MIDI', 1, 0, 0)\n",
      "1 (b'CoreMIDI', b'CASIO USB-MIDI', 0, 1, 0)\n"
     ]
    }
   ],
   "source": [
    "import pygame.midi\n",
    "\n",
    "def print_devices():\n",
    "    for n in range(pygame.midi.get_count()):\n",
    "        print (n,pygame.midi.get_device_info(n))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pygame.midi.init()\n",
    "    print_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pygame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[39mprint\u001b[39m (number_to_note(note_number), velocity)\n\u001b[1;32m     29\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 30\u001b[0m     pygame\u001b[39m.\u001b[39mmidi\u001b[39m.\u001b[39minit()\n\u001b[1;32m     31\u001b[0m     my_input \u001b[39m=\u001b[39m pygame\u001b[39m.\u001b[39mmidi\u001b[39m.\u001b[39mInput(\u001b[39m0\u001b[39m) \u001b[39m#only in my case the id is 0\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     readInput(my_input)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pygame' is not defined"
     ]
    }
   ],
   "source": [
    "notes = ['c', 'c#', 'd', 'd#', 'e', 'f', 'f#', 'g', 'g#', 'a', 'a#', 'b']\n",
    "keys = np.array([x+str(y) for y in range(0,9) for x in notes])\n",
    "# Trim to correct # keys\n",
    "start = np.where(keys == 'a0')[0][0]\n",
    "end = np.where(keys == 'c8')[0][0]\n",
    "keys = keys[start:end+1]\n",
    "midi_num=[]\n",
    "n=21\n",
    "for i in range(len(keys)):    \n",
    "    midi_num.append(n)\n",
    "    n=n+1\n",
    "\n",
    "def number_to_note(number):\n",
    "    index = midi_num.index(number)\n",
    "    note_played=(keys[index])\n",
    "    return note_played\n",
    "\n",
    "def readInput(input_device):\n",
    "    while True:\n",
    "        if input_device.poll():\n",
    "            event = input_device.read(1)[0]\n",
    "            \n",
    "            data = event[0]\n",
    "            timestamp = event[1]\n",
    "            note_number = data[1]\n",
    "            velocity = data[2]\n",
    "            print (number_to_note(note_number), velocity)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pygame.midi.init()\n",
    "    my_input = pygame.midi.Input(0) #only in my case the id is 0\n",
    "    readInput(my_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# White keys are in Uppercase and black keys (sharps) are in lowercase\n",
    "octave = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'] \n",
    "base_freq = 440 #Frequency of Note A4\n",
    "keys = np.array([x+str(y) for y in range(0,9) for x in octave])\n",
    "# Trim to correct # keys\n",
    "start = np.where(keys == 'A0')[0][0]\n",
    "end = np.where(keys == 'C8')[0][0]\n",
    "keys = keys[start:end+1]\n",
    "\n",
    "note_freqs = list(([2**((n-48)/12)*base_freq for n in range(len(keys))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261.6255653005986, 293.6647679174076, 329.6275569128699, 349.2282314330039, 391.99543598174927]\n"
     ]
    }
   ],
   "source": [
    "c_major_scale_freqs=[]\n",
    "c_major_scale=['C4', 'D4', 'E4', 'F4', 'G4']\n",
    "for i in range(len(keys)):\n",
    "    for j in range(5):\n",
    "        if c_major_scale[j]==keys[i]:\n",
    "            c_major_scale_freqs.append(note_freqs[i])\n",
    "print(c_major_scale_freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_value(input_list, input_value):\n",
    "\n",
    "  arr = np.asarray(input_list)\n",
    "\n",
    "  i = (np.abs(arr - input_value)).argmin()\n",
    "\n",
    "  return arr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "CHUNK = 1024*4          # samples per frame\n",
    "FORMAT = pyaudio.paInt16     # audio format (bytes per sample?)\n",
    "CHANNELS = 1                 # single channel for microphone\n",
    "RATE = 48000                 # samples per second\n",
    "RECORD_SECONDS = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "p.get_device_info_by_index(3)['defaultSampleRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* listening\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "* waiting\n",
      "recording\n",
      "* done\n"
     ]
    }
   ],
   "source": [
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "#os.remove('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "# create matplotlib figure and axes\n",
    "#fig, (ax1, ax2) = plt.subplots(2, figsize=(15, 7))\n",
    "\n",
    "# pyaudio class instance\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "#p.get_device_info_by_index(3)['defaultSampleRate']\n",
    "\n",
    "# stream object to get data from microphone\n",
    "stream = p.open(\n",
    "    format=FORMAT,\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input_device_index =3, #change this according to the mic port on your computer\n",
    "    input=True,output=True,\n",
    "    frames_per_buffer=CHUNK\n",
    ")\n",
    "frames = []\n",
    "print(\"* listening\")\n",
    "\n",
    "while 1:\n",
    "  \n",
    "\n",
    "    data = stream.read(CHUNK, exception_on_overflow = False)\n",
    "    data_chunk=array('h',data)\n",
    "    vol=max(data_chunk)\n",
    "    if vol >= 400:\n",
    "        print(\"recording\")\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)): \n",
    "            stream.write(data, CHUNK)\n",
    "            frames.append(data)\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        print(\"* waiting\")\n",
    "\n",
    "print(\"* done\")\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "p.terminate()\n",
    "file_path='/Users/emmarobinson/Downloads/piano_audio.wav' #change this according to your computer file\n",
    "file_name = file_path.split('/')[-1]\n",
    "wf = wave.open(file_path, \"wb\")\n",
    "# set the channels\n",
    "wf.setnchannels(CHANNELS)\n",
    "# set the sample format\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "# set the sample rate\n",
    "wf.setframerate(RATE)\n",
    "# write the frames as bytes\n",
    "wf.writeframes(b\"\".join(frames))\n",
    "# close the file\n",
    "wf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/Users/emmarobinson/Downloads/piano_audio_new.wav'>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I dont know if we need this tbh\n",
    "sound = AudioSegment.from_file(file_path, format = 'wav') \n",
    "audio_chunks = split_on_silence(sound\n",
    "                            ,min_silence_len = 100\n",
    "                            ,silence_thresh = -45\n",
    "                            ,keep_silence = 50\n",
    "                        )\n",
    "\n",
    "# Putting the file back together\n",
    "combined = AudioSegment.empty()\n",
    "for chunk in audio_chunks:\n",
    "    combined += chunk\n",
    "combined.export(f'/Users/emmarobinson/Downloads/piano_audio_new.wav', format = 'wav') #change this according to your computer file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 190ms/step\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wav.read('/Users/emmarobinson/Downloads/piano_audio.wav') #change this according to your computer file\n",
    "time, frequency, confidence, activation = crepe.predict(audio, sr, viterbi=True, model_capacity=\"small\")\n",
    "freq1=np.array([np.mean(frequency)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C#6']\n"
     ]
    }
   ],
   "source": [
    "song_notes=[]\n",
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    song_notes.append(keys[index])\n",
    "    print(song_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(freq1)):\n",
    "    note=closest_value(note_freqs,freq1[i])\n",
    "    index = note_freqs.index(note)\n",
    "    played_note=keys[index]\n",
    "\n",
    "x=0\n",
    "if played_note==c_major_scale[x]:\n",
    "    print(\"yay\")\n",
    "else:\n",
    "        print(\"try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wav.read('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "audio_segment = AudioSegment.from_file('/Users/emmarobinson/Downloads/piano_audio_new.wav') #change this according to your computer file\n",
    "\n",
    "duration = len(audio_segment)/1000\n",
    "\n",
    "# calculate the length of our chunk in the np.array using sample rate\n",
    "chunk = int(rate * duration)\n",
    "\n",
    "# length of delimiting 1600hz tone\n",
    "offset = int(rate * 0.005)\n",
    "\n",
    "# number of bits in the audio data to decode\n",
    "bits = int(len(data) / chunk)\n",
    "\n",
    "def get_freq(bit):\n",
    "    # start position of the current bit\n",
    "    strt = (chunk * bit) \n",
    "    \n",
    "    # remove the delimiting 1600hz tone\n",
    "    end = (strt + chunk) \n",
    "   \n",
    "    \n",
    "    # slice the array for each bit\n",
    "    sliced = data[strt:end]\n",
    "\n",
    "    w = np.fft.fft(sliced)\n",
    "    w=np.absolute(w)\n",
    "    freqs = np.fft.fftfreq(len(w))\n",
    "\n",
    "    \n",
    "\n",
    "    # Find the peak in the coefficients\n",
    "    idx = np.argmax(np.abs(w))\n",
    "    freq = freqs[idx]\n",
    "    freq_in_hertz = abs(freq * rate)\n",
    "    return freq_in_hertz\n",
    "\n",
    "decoded_freqs = [get_freq(bit) for bit in range(bits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Device id  0  -  Built-in Microphone\n",
      "Input Device id  3  -  Blue Snowball \n",
      "Input Device id  4  -  Microsoft Teams Audio\n",
      "Input Device id  5  -  ZoomAudioDevice\n"
     ]
    }
   ],
   "source": [
    "p = pyaudio.PyAudio()\n",
    "info = p.get_host_api_info_by_index(0)\n",
    "numdevices = info.get('deviceCount')\n",
    "\n",
    "for i in range(0, numdevices):\n",
    "    if (p.get_device_info_by_host_api_device_index(0, i).get('maxInputChannels')) > 0:\n",
    "        print(\"Input Device id \", i, \" - \", p.get_device_info_by_host_api_device_index(0, i).get('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
